# VK Technopark-BMSTU | SEM II | ML OPS
================================================================

Хажиев Роберт Ринатович.

Группа ML-21.

Преподаватели: Михаил Марюфич


**Homeworks:**

<details>
  <summary>HW1: Production ready project</summary>

## Требуется сделать "production ready" проект для решения задачи классификации, то есть написать код для обучения и предикта, покрыть его тестами и тд

Для обучения модели, можете использовать датасет https://www.kaggle.com/datasets/cherngs/heart-disease-cleveland-uci, либо иной небольшой датасет для классификации (если используете другой, то опишите какой и как его получить в readme)

Пример подобного рассматривали на паре https://github.com/made-ml-in-prod-2021/ml_project_example.  

Код должен находиться в папке ml_project, ветка должна называться homework1.
Если вы студент MADE,то добавьте к пуллревесту тэг -- MADE, если вы студент Технопарка -- добавьте тэг TECHNOPARK 

**Критерии (указаны максимальные баллы, по каждому критерию ревьюер может поставить баллы частично):**

0) В описании к пулл реквесту описаны основные "архитектурные" и тактические решения, которые сделаны в вашей работе. В общем, описание того, что именно вы сделали и для чего, чтобы вашим ревьюерам было легче понять ваш код (1 балл)
1) В пулл-реквесте проведена самооценка, распишите по каждому пункту выполнен ли критерий или нет и на сколько баллов(частично или полностью) (1 балл)

2) Выполнено EDA, закоммитьте ноутбук в папку с ноутбуками (1 балл)
   Вы так же можете построить в ноутбуке прототип(если это вписывается в ваш стиль работы)

   Можете использовать не ноутбук, а скрипт, который сгенерит отчет, закоммитьте и скрипт и отчет (за это + 1 балл)

3) Написана функция/класс для тренировки модели, вызов оформлен как утилита командной строки, записана в readme инструкцию по запуску (3 балла)
4) Написана функция/класс predict (вызов оформлен как утилита командной строки), которая примет на вход артефакт/ы от обучения, тестовую выборку (без меток) и запишет предикт по заданному пути, инструкция по вызову записана в readme (3 балла)

5) Проект имеет модульную структуру (2 балла)
6) Использованы логгеры (2 балла)

7) Написаны тесты на отдельные модули и на прогон обучения и predict (3 балла)

8) Для тестов генерируются синтетические данные, приближенные к реальным (2 балла)
   - можно посмотреть на библиотеки https://faker.readthedocs.io/, https://feature-forge.readthedocs.io/en/latest/
   - можно просто руками посоздавать данных, собственноручно написанными функциями.

9) Обучение модели конфигурируется с помощью конфигов в json или yaml, закоммитьте как минимум 2 корректные конфигурации, с помощью которых можно обучить модель (разные модели, стратегии split, preprocessing) (3 балла)
10) Используются датаклассы для сущностей из конфига, а не голые dict (2 балла)

11) Напишите кастомный трансформер и протестируйте его (3 балла)
   https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156

12) В проекте зафиксированы все зависимости (1 балл)
13) Настроен CI для прогона тестов, линтера на основе github actions (3 балла).
Пример с пары: https://github.com/demo-ml-cicd/ml-python-package

PS: Можно использовать cookiecutter-data-science  https://drivendata.github.io/cookiecutter-data-science/ , но поудаляйте папки, в которые вы не вносили изменения, чтобы не затруднять ревью

Дополнительные баллы=)
- Используйте hydra для конфигурирования (https://hydra.cc/docs/intro/) - 3 балла

Mlflow
- разверните локально mlflow или на какой-нибудь виртуалке (1 балл)
- залогируйте метрики (1 балл)
- воспользуйтесь Model Registry для регистрации модели(1 балл)
  Приложите скриншот с вашим mlflow run
  DVC
- выделите в своем проекте несколько entrypoints в виде консольных утилит (1 балл).
  Пример: https://github.com/made-ml-in-prod-2021/ml_project_example/blob/main/setup.py#L16
  Но если у вас нет пакета, то можно и просто несколько скриптов

- добавьте датасет под контроль версий (1 балл)
- сделайте dvc пайплайн(связывающий запуск нескольких entrypoints) для изготовления модели(1 балл)

Для большего удовольствия в выполнении этих частей рекомендуется попробовать подключить удаленное S3 хранилище(например в Yandex Cloud, VK Cloud Solutions или Selectel)
</details>

<details>
  <summary>HW2: Online Inference</summary>
  
В прошлом ДЗ вы обучили модель для решения задачи классификации (по умолчанию использовался датасет https://www.kaggle.com/datasets/cherngs/heart-disease-cleveland-uci). Ваше следующее задание, это обернуть ее в вид, пригодный для использования в режиме онлайн.

Весь код должен находиться в том же репозитории, но в отдельной папке _online_inference_. 

**Основная часть:**

1) Оберните inference вашей модели в rest сервис на FastAPI, должен быть endpoint /predict (3 балла)
2) Напишите endpoint /health, который должен возращать 200, если ваша модель готова к работе (такой чек особенно актуален, если делаете доп задание про скачивание из хранилища) (1 балл)
3) Напишите unit тест для /predict (https://fastapi.tiangolo.com/tutorial/testing/, https://flask.palletsprojects.com/en/1.1.x/testing/) (3 балла)

4) Напишите скрипт, который будет делать запросы к вашему сервису (2 балла)

5) Напишите Dockerfile, соберите на его основе образ и запустите локально контейнер (`docker build`, `docker run`). Внутри контейнера должен запускаться сервис, написанный в предущем пункте. Закоммитьте его, напишите в README.md корректную команду сборки (4 балла)

6) Опубликуйте образ в https://hub.docker.com/, используя `docker push` (вам потребуется зарегистрироваться) (2 балла)

7) Опишите в README.md корректные команды `docker pull/run`, которые должны привести к тому, что локально поднимется на inference ваша модель.
   Убедитесь, что вы можете протыкать его скриптом из пункта 3 (1 балл)

8) Проведите самооценку - распишите в реквесте какие пункты выполнили и на сколько баллов, укажите общую сумму баллов (1 балл)


**Дополнительная часть**:

1) Ваш сервис скачивает модель из S3 или любого другого хранилища при старте, путь для скачивания передается через переменные окружения (+2 доп балла)
2) Оптимизируйте размер docker image. Опишите в README.md, что вы предприняли для сокращения размера и каких результатов удалось добиться. Должно получиться мини исследование -- я сделал тото и получился такой-то результат (+2 доп балла)
https://docs.docker.com/develop/develop-images/dockerfile_best-practices/
3) Сделайте валидацию входных данных https://pydantic-docs.helpmanual.io/usage/validators/ . Например, порядок колонок не совпадает с трейном, типы, допустимые максимальные и минимальные значения. Проявите фантазию, это доп. баллы, проверка не должна быть тривиальной. Вы можете сохранить вместе с моделью доп информацию о структуре входных данных, если это нужно (+2 доп балла).
https://fastapi.tiangolo.com/tutorial/handling-errors/ -- возращайте 400, в случае, если валидация не пройдена

**Процедура сдачи**:

После выполнения ДЗ создаем пулл реквест, в ревьюеры добавляем  Mikhail-M, ждем комментариев (на которые нужно ответить) и/или оценки.
Ветка должна называться _homework2_.

Пожалуйста добавьте к своему пулл реквесту метку _hw2_. Если вы студент MADE, то дополнительно укажите тэг -- _MADE_, если вы студент Технопарка -- тэг _TECHNOPARK_.

**Сроки выполнения**:

Мягкий дедлайн: **30 мая 23:59**

Жесткий дедлайн:  **6 июня 23:59**

**Важно:** после мягкого дедлайна все полученные баллы умножаются на 0.6
</details>

<details>
  <summary>HW3: Airflow ML Dags</summary>

Суть этого ДЗ -- познакомиться с `airflow`.

Легенда:
1) Откуда-то берутся данные... Мы их используем для обучения МЛ модельки для задачи классификации.
2) Еженедельно, мы переобучаем модель на новых данных, ручками смотрим на метрики и если класс, то выкатываем ее на прод.
3) Ежедневно, текущая выбранная нами модель скорит данные и записывает предсказания куда-то.
4) Эти предсказания используют -- все счастливы =)

В ДЗ предлагается на основе `airflow` реализовать описанную выше схему, к деталям:

**Основная часть:**

0) Поднимите airflow локально, используя `docker compose` (можно использовать из примера https://github.com/made-ml-in-prod-2021/airflow-examples/)
1) Реализуйте dag, который генерирует данные для обучения модели (генерируйте данные -- можете использовать как генератор синтетики из первой дз, так и что-то из датасетов sklearn). Вам важно проэмулировать ситуации постоянно поступающих данных (5 баллов)

    - записывайте данные в `/data/raw/{{ ds }}/data.csv` и `/data/raw/{{ ds }}/target.csv`

2) Реализуйте dag, который обучает модель еженедельно, используя данные за текущий день. В вашем пайплайне должно быть как минимум 4 стадии, но дайте волю своей фантазии =) (10 баллов)

    - подготовить данные для обучения (например, считать из `/data/raw/{{ ds }}` и положить `/data/processed/{{ ds }}/train_data.csv`)
    - расплитить их на train/val
    - обучить модель на train, сохранить в `/data/models/{{ ds }}`
    - провалидировать модель на val (сохранить метрики к модельке)

3) Реализуйте dag, который использует модель ежедневно (5 баллов)
    - принимает на вход данные из пункта 1 (`data.csv`)
    - считывает путь до модельки из airflow variables (идея в том, что когда нам нравится другая модель и мы хотим ее на прод)
    - делает предсказание и записывает их в `/data/predictions/{{ ds }}/predictions.csv`

4) Вы можете выбрать 2 пути для выполнения ДЗ:
    - поставить все необходимые пакеты в образ с `airflow` и использовать `BashOperator`, `PythonOperator` (1 балл)
    - использовать `DockerOperator` -- тогда выполнение каждой из тасок должно запускаться в собственном контейнере  
      * один из дагов реализован с помощью `DockerOperator` (5 баллов)
      * все даги реализованы только с помощью `DockerOperator` (пример https://github.com/made-ml-in-prod-2021/airflow-examples/blob/main/dags/11_docker.py). По технике, вы можете использовать такую же структуру как в примере, пакуя в разные докеры скрипты, можете использовать общий докер с вашим пакетом, но с разными точками входа для разных тасок. Прикольно, если вы покажете, что для разных тасок можно использовать разный набор зависимостей (10 баллов)

      https://github.com/made-ml-in-prod-2021/airflow-examples/blob/main/dags/11_docker.py#L27 в этом месте пробрасывается путь с хостовой машины, используйте здесь путь типа `/tmp` или считывайте из переменных окружения.

5) Традиционно, самооценка (1 балл)

**Дополнительная часть**:

6) Реализуйте сенсоры на то, что данные готовы для дагов тренировки и обучения (+3 доп балла)
7) Протестируйте ваши даги https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html (+5 доп баллов) 
8) В `docker compose` так же настройте поднятие `mlflow` и запишите туда параметры обучения, метрики и артефакт (модель) (+5 доп баллов)
9) Вместо пути в airflow variables используйте API Mlflow Model Registry. Даг для инференса должен подхватывать последнюю продакшен модель (+5 доп баллов)
10) Настройте alert в случае падения дага https://www.astronomer.io/guides/error-notifications-in-airflow (+3 доп балла)

Чтобы получить баллы, сделайте скриншоты списка всех дагов и каждого графа по отдельности (в исполненном без ошибок виде) и прикрепите их в описание пулл реквеста.

**Процедура сдачи**:

Весь код должен находиться в том же репозитории, но в отдельной папке _airflow_ml_dags_. 

После выполнения ДЗ создаем пулл реквест, в ревьюеры добавляем  Mikhail-M, ждем комментариев (на которые нужно ответить) и/или оценки.
Ветка должна называться _homework3_.

Пожалуйста добавьте к своему пулл реквесту метку _hw3_. Если вы студент MADE, то дополнительно укажите тэг -- _MADE_, если вы студент Технопарка -- тэг _TECHNOPARK_.

**Сроки выполнения**:

Мягкий дедлайн: **20 июня 23:59**

Жесткий дедлайн:  **27 июня 23:59**

**Важно:** после мягкого дедлайна все полученные баллы умножаются на 0.6
</details>